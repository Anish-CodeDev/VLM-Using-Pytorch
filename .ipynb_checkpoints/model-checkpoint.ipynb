{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30efb50-56bd-4598-9ad9-b9bfd99e6200",
   "metadata": {
    "id": "b30efb50-56bd-4598-9ad9-b9bfd99e6200"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A-29YqKCQEyQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-29YqKCQEyQ",
    "outputId": "baf70462-bcb9-4211-f662-60963af7fa2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.2.0\n",
      "  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (4.14.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.0)\n",
      "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0) (1.3.0)\n",
      "Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.2.0\n",
      "    Uninstalling triton-3.2.0:\n",
      "      Successfully uninstalled triton-3.2.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cu124\n",
      "    Uninstalling torch-2.6.0+cu124:\n",
      "      Successfully uninstalled torch-2.6.0+cu124\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.0 which is incompatible.\n",
      "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OIdGlLROSYBS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIdGlLROSYBS",
    "outputId": "382c345a-ebba-4712-86b4-53af0f8d4e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision==0.17\n",
      "  Downloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17) (2.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17) (2.32.3)\n",
      "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.17) (11.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (4.14.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchvision==0.17) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchvision==0.17) (12.5.82)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.17) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0->torchvision==0.17) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->torchvision==0.17) (1.3.0)\n",
      "Downloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0+cu124\n",
      "    Uninstalling torchvision-0.21.0+cu124:\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\n",
      "Successfully installed torchvision-0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IpeTjKWYesTT",
   "metadata": {
    "collapsed": true,
    "id": "IpeTjKWYesTT",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8Rt0ughsF_BF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8Rt0ughsF_BF",
    "outputId": "a612b1a3-f373-40bf-a979-4597de9d27f4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.0.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hpM8rmaSS1nH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpM8rmaSS1nH",
    "outputId": "ff2bef71-f9d6-4fb2-c77f-1d5343d75f21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.0.2\n",
      "Uninstalling numpy-2.0.2:\n",
      "  Successfully uninstalled numpy-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy==2.0.2 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xoGhgi8XAFqE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "xoGhgi8XAFqE",
    "outputId": "3a1742fa-e87a-4ccf-aab9-4df0ae025380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.0\n",
      "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "f59d7b734b264da793a861d8afe173bc",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install numpy==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Idtkw2-EapR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Idtkw2-EapR",
    "outputId": "67e71624-037f-4189-b27d-b53b0c8c7104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.17.0\n",
      "  Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.32.3)\n",
      "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (1.26.0)\n",
      "Collecting torchdata==0.7.1 (from torchtext==0.17.0)\n",
      "  Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (4.14.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2.2.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.4.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext==0.17.0) (12.5.82)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0->torchtext==0.17.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->torchtext==0.17.0) (1.3.0)\n",
      "Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchdata, torchtext\n",
      "  Attempting uninstall: torchdata\n",
      "    Found existing installation: torchdata 0.11.0\n",
      "    Uninstalling torchdata-0.11.0:\n",
      "      Successfully uninstalled torchdata-0.11.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torchdata-0.7.1 torchtext-0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29f1c3-a469-48fe-8db1-ace8adbeff54",
   "metadata": {
    "id": "ed29f1c3-a469-48fe-8db1-ace8adbeff54"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vit_b_16,ViT_B_16_Weights\n",
    "import math\n",
    "from PIL import Image\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import GloVe,build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from google import genai\n",
    "from google.colab import drive,auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UmZIecGWHCNu",
   "metadata": {
    "id": "UmZIecGWHCNu"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2R36dQFIrZrq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2R36dQFIrZrq",
    "outputId": "44558407-1c26-4cb7-f8b9-a091b709be18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d18ffc7-9064-4470-a95c-5bf1896e05c0",
   "metadata": {
    "id": "2d18ffc7-9064-4470-a95c-5bf1896e05c0"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12913a3-8bd5-48d1-96c7-f7ecbfb5ac01",
   "metadata": {
    "id": "a12913a3-8bd5-48d1-96c7-f7ecbfb5ac01"
   },
   "outputs": [],
   "source": [
    "# Convert all the images to a tensor compatible with the vit image encoder.\n",
    "weights = ViT_B_16_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "img = Image.open(\"/content/drive/MyDrive/Datasets/example.jpg\").convert('RGB')\n",
    "\n",
    "img_tensor = preprocess(img).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c73d7-aa98-4218-99f4-62e996ae0030",
   "metadata": {
    "id": "fc8c73d7-aa98-4218-99f4-62e996ae0030"
   },
   "outputs": [],
   "source": [
    "def process_image(img_path):\n",
    "    img = Image.open(f\"/content/drive/MyDrive/Datasets/Flickr8k_Dataset/Flicker8k_Dataset/{img_path}\").convert('RGB')\n",
    "    return preprocess(img).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c2ec3-8dde-49b3-a8cd-cc17cf224930",
   "metadata": {
    "id": "6b4c2ec3-8dde-49b3-a8cd-cc17cf224930",
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_id,caption = [],[]\n",
    "with open('/content/drive/MyDrive/Datasets/Flickr8k_text/captions.txt','r') as f:\n",
    "    for s in f.read().split('\\n'):\n",
    "        try:\n",
    "            if(os.path.exists('/content/drive/MyDrive/Datasets/Flickr8k_Dataset/Flicker8k_Dataset/' + s.split()[0].split('#')[0])):\n",
    "                img_id.append(s.split()[0].split('#')[0])\n",
    "                cap_str = ''\n",
    "                for w in s.split()[1:]:\n",
    "                    cap_str += w + \" \"\n",
    "\n",
    "\n",
    "                caption.append(cap_str)\n",
    "\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aec083-8422-4d92-9a5f-c4b1ae345f6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69aec083-8422-4d92-9a5f-c4b1ae345f6e",
    "outputId": "d58f92cb-d78b-46af-908d-c1cb7632e629"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:38, 5.43MB/s]                           \n",
      "100%|█████████▉| 399999/400000 [00:11<00:00, 33548.98it/s]\n"
     ]
    }
   ],
   "source": [
    "glove_embedding = GloVe(name='6B',dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b861d43-7ea8-446c-89b6-2bc737e5b490",
   "metadata": {
    "id": "7b861d43-7ea8-446c-89b6-2bc737e5b490"
   },
   "outputs": [],
   "source": [
    "tokenizer =  get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35fba5a-b54e-42f4-8878-78a9f08a6033",
   "metadata": {
    "id": "f35fba5a-b54e-42f4-8878-78a9f08a6033"
   },
   "outputs": [],
   "source": [
    "def yield_tokens(cap):\n",
    "    for c in cap:\n",
    "        yield tokenizer(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c037606a-6c7f-4038-843b-83f881a0d593",
   "metadata": {
    "id": "c037606a-6c7f-4038-843b-83f881a0d593"
   },
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(yield_tokens(caption),specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f5bd61-b3e6-4c41-8e3e-7b024626784b",
   "metadata": {
    "id": "e1f5bd61-b3e6-4c41-8e3e-7b024626784b"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d197ec-6957-4dcd-b99d-db029a98aefd",
   "metadata": {
    "id": "b7d197ec-6957-4dcd-b99d-db029a98aefd"
   },
   "outputs": [],
   "source": [
    "def collate_img_function():\n",
    "    img_arr = []\n",
    "    for img in img_id[:2000]:\n",
    "\n",
    "            img_arr.append(process_image(img))\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe7e12-d1a0-4a05-a829-0bd4c92cce8b",
   "metadata": {
    "collapsed": true,
    "id": "4cfe7e12-d1a0-4a05-a829-0bd4c92cce8b",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "img_tensor_arr = collate_img_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfOQ3O1OZEgF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bfOQ3O1OZEgF",
    "outputId": "7df73681-5439-401d-df01-5ab039fca8f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_tensor_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e1a2a-d3eb-4f9c-88b1-b384198d543d",
   "metadata": {
    "id": "767e1a2a-d3eb-4f9c-88b1-b384198d543d"
   },
   "outputs": [],
   "source": [
    "img_tensor_arr = torch.stack(img_tensor_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33114cf1-40a2-4b93-a0db-ebdf117f1353",
   "metadata": {
    "id": "33114cf1-40a2-4b93-a0db-ebdf117f1353"
   },
   "outputs": [],
   "source": [
    "def collate_text_function():\n",
    "    cap_arr =  []\n",
    "    for cap in caption[:2000]:\n",
    "        cap_arr.append(torch.tensor(vocab(tokenizer(cap)),dtype=torch.int64))\n",
    "\n",
    "    cap_arr = pad_sequence(cap_arr,batch_first=True)\n",
    "    return cap_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02efc4de-bffa-4c28-8a63-7ab72a1c542c",
   "metadata": {
    "id": "02efc4de-bffa-4c28-8a63-7ab72a1c542c"
   },
   "outputs": [],
   "source": [
    "cap_tensor_arr = collate_text_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furuTZza9L7S",
   "metadata": {
    "id": "furuTZza9L7S"
   },
   "outputs": [],
   "source": [
    "cap_tensor_arr = pad_sequence([\n",
    "    torch.nn.functional.pad(cap,(0,50-31),'constant',0) for cap in cap_tensor_arr\n",
    "],batch_first=True,padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ro6g9nxd-BfQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ro6g9nxd-BfQ",
    "outputId": "80af7bf2-ce09-4f91-bbea-3c089b72ba1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 50])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_tensor_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c4f709-efe5-4225-89ac-db18159db958",
   "metadata": {
    "id": "35c4f709-efe5-4225-89ac-db18159db958"
   },
   "outputs": [],
   "source": [
    "img_tensor_arr = img_tensor_arr.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a3b65-c2a4-45a6-98e8-07f407981c59",
   "metadata": {
    "id": "8c4a3b65-c2a4-45a6-98e8-07f407981c59"
   },
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(img_tensor_arr,cap_tensor_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069b9dd-c911-4b81-87c2-482bdca26d00",
   "metadata": {
    "id": "0069b9dd-c911-4b81-87c2-482bdca26d00"
   },
   "outputs": [],
   "source": [
    "train_dataset,test_dataset = train_test_split(dataset,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a211cef-1466-45a9-a1fd-36835a59b9cf",
   "metadata": {
    "id": "4a211cef-1466-45a9-a1fd-36835a59b9cf"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=50,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wZ9kCpOEPCHt",
   "metadata": {
    "id": "wZ9kCpOEPCHt"
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,batch_size=50,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885737d8-e821-4533-b6d7-554f8435d480",
   "metadata": {
    "id": "885737d8-e821-4533-b6d7-554f8435d480"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model,seq_len):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        pe = torch.zeros(seq_len,d_model)\n",
    "        positions = torch.arange(0,seq_len,dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0,d_model,2).float() * (-math.log(10000)/d_model)\n",
    "        )\n",
    "        pe[:,0::2] = torch.sin(positions * div_term)\n",
    "        pe[:,1::2] = torch.cos(positions * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\",pe)\n",
    "\n",
    "    def forward(self,x):\n",
    "       x = x + self.pe\n",
    "       return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c106c-8b38-453a-94f3-5d59a89849a8",
   "metadata": {
    "id": "8b7c106c-8b38-453a-94f3-5d59a89849a8"
   },
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mvdub7ixKfUl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mvdub7ixKfUl",
    "outputId": "2fd85dee-c167-41de-b45c-5bdb589693c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100%|██████████| 330M/330M [00:02<00:00, 151MB/s]\n"
     ]
    }
   ],
   "source": [
    "vit_encoder = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbafed-2fde-4a57-af31-0c5355949b5a",
   "metadata": {
    "id": "03bbafed-2fde-4a57-af31-0c5355949b5a"
   },
   "outputs": [],
   "source": [
    "for n in range(12):\n",
    "    vit_encoder.encoder.layers[n].mlp[0] = LoRADenseLayer(vit_encoder.encoder.layers[n].mlp[0],2,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227514f0-b66c-4b8f-86a9-b32e257bef4a",
   "metadata": {
    "id": "227514f0-b66c-4b8f-86a9-b32e257bef4a"
   },
   "outputs": [],
   "source": [
    "class ImageCaptioningModel(nn.Module):\n",
    "    def __init__(self,vocab_size,n_head,num_encoder_layers,num_decoder_layers,max_seq_len): # n-head = 12,num_encoder_layers=6,num_decoder_layer=6\n",
    "        super().__init__()\n",
    "        self.vision_encoder = vit_encoder\n",
    "        self.vision_encoder.head = nn.Identity() # Does'nt modify anything\n",
    "\n",
    "        self.enc_projection = nn.Linear(1000,50)\n",
    "        # Text decoder\n",
    "        self.token_embedding  = nn.Embedding.from_pretrained(glove_embedding.vectors,freeze=True)\n",
    "        self.d_model = 50\n",
    "        self.positional_encoding = PositionalEncoding(self.d_model,max_seq_len)\n",
    "\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=self.d_model,nhead=n_head,batch_first=True)\n",
    "        self.decoder_transformer = nn.TransformerDecoder(decoder_layer,num_layers=num_decoder_layers)\n",
    "        self.output_linear = nn.Linear(self.d_model,self.d_model)\n",
    "\n",
    "    def forward(self,img,cap_tokens,inference):\n",
    "        enc_out = self.vision_encoder(img)\n",
    "        seq_len = cap_tokens.shape[1]\n",
    "        caption_embeddings= self.token_embedding(cap_tokens) * math.sqrt(self.d_model) + self.positional_encoding(cap_tokens)\n",
    "\n",
    "        mask = nn.Transformer.generate_square_subsequent_mask(50,device=device)\n",
    "        print(caption_embeddings.shape)\n",
    "        print(enc_out.shape)\n",
    "        if inference:\n",
    "\n",
    "          decoder_output = self.decoder_transformer(\n",
    "              tgt=caption_embeddings,\n",
    "              memory=self.enc_projection(enc_out).unsqueeze(0),\n",
    "              tgt_mask=mask.unsqueeze(0).expand(50,-1,-1) # num_heads * batch_size => 50*50=2500\n",
    "          )\n",
    "        else:\n",
    "          decoder_output = self.decoder_transformer(\n",
    "              tgt=caption_embeddings,\n",
    "              memory=torch.transpose(self.enc_projection(enc_out).unsqueeze(0),1,2).expand(50,-1,-1),\n",
    "              tgt_mask=mask.unsqueeze(0).expand(2500,-1,-1) # num_heads * batch_size => 50*50=2500\n",
    "          )\n",
    "\n",
    "        logits = self.output_linear(decoder_output)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da953b01-3880-4d4b-9090-5094b76ac05a",
   "metadata": {
    "id": "da953b01-3880-4d4b-9090-5094b76ac05a"
   },
   "outputs": [],
   "source": [
    "model = ImageCaptioningModel(vocab_size,50,6,6,50).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196b1c0-05df-4b06-a3df-0ff29015e46a",
   "metadata": {
    "id": "c196b1c0-05df-4b06-a3df-0ff29015e46a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LoRA(nn.Module):\n",
    "    def __init__(self,rank,in_features,out_features,alpha):\n",
    "        super().__init__()\n",
    "        standard_deviation = 1/torch.sqrt(torch.tensor(rank).float())\n",
    "        self.A = nn.Parameter(torch.randn(in_features,rank) * standard_deviation)\n",
    "        self.B = nn.Parameter(torch.zeros(rank,out_features))\n",
    "        self.alpha = alpha\n",
    "        self.rank = rank\n",
    "    def forward(self,x):\n",
    "        return (self.alpha/self.rank) * (x @self.A @ self.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff2180a-aaf1-4499-9efa-b6dcfa974338",
   "metadata": {
    "id": "fff2180a-aaf1-4499-9efa-b6dcfa974338"
   },
   "outputs": [],
   "source": [
    "class LoRADenseLayer(nn.Module):\n",
    "    def __init__(self,linear,rank,alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear.to(device)\n",
    "        in_features = linear.in_features\n",
    "        out_features = linear.out_features\n",
    "        self.lora = LoRA(rank,in_features,out_features,alpha).to(device)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c1398-1321-446a-bbe7-8db4966eb57c",
   "metadata": {
    "id": "c20c1398-1321-446a-bbe7-8db4966eb57c"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c7db4-6dc4-4864-967b-4a362f7a6412",
   "metadata": {
    "id": "564c7db4-6dc4-4864-967b-4a362f7a6412"
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1)\n",
    "scheduler= torch.optim.lr_scheduler.StepLR(optimizer,1.0,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937e86b-fcfc-482b-ae27-75bd6b5b8a14",
   "metadata": {
    "id": "3937e86b-fcfc-482b-ae27-75bd6b5b8a14"
   },
   "outputs": [],
   "source": [
    "def train_model(model,criterion,optimizer,epochs=1):\n",
    "    acc_epoch = []\n",
    "    cum_loss_list = []\n",
    "    time_start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        cum_loss = 0\n",
    "\n",
    "        for img,cap in train_dataloader:\n",
    "            print('Started')\n",
    "            optimizer.zero_grad()\n",
    "            img,cap = img.to(device),cap.to(device)\n",
    "            output = model(img,cap,False)\n",
    "            cap = cap.unsqueeze(0).expand(50,-1,-1)\n",
    "            loss = criterion(output,cap.float())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(),0.1)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            cum_loss += loss.item()\n",
    "            print('Step Completed')\n",
    "        torch.save(model.state_dict,\"/content/drive/MyDrive/model_weights_pytorch/model.pt\")\n",
    "        eval_acc = evaluate(model)\n",
    "        acc_epoch.append(eval_acc)\n",
    "        cum_loss_list.append(cum_loss)\n",
    "        print(\"Epoch\",epoch,\"Loss:\",cum_loss)\n",
    "\n",
    "    print('Time taken: ',time.time()-time_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gIFLqpEee1-T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIFLqpEee1-T",
    "outputId": "2b67fd32-198a-4f0a-fa17-9383a012f40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.8000e+01, 1.5000e+01, 3.4000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0000e+00, 1.7300e+02, 3.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0000e+00, 1.6000e+01, 2.2000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.0000e+00, 1.5000e+01, 3.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [2.5090e+03, 1.1000e+01, 4.1600e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0000e+00, 5.2820e+03, 2.6000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "for img,cap in train_dataloader:\n",
    "  print(cap.float())\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KfIx9c64fqN7",
   "metadata": {
    "id": "KfIx9c64fqN7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07269484-5534-446d-99ca-cdd58a501c1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "07269484-5534-446d-99ca-cdd58a501c1e",
    "outputId": "777f9604-22e3-4715-8f40-0347857c20e1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-3523702772>:17: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(),0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Epoch 0 Loss: 291428.50146484375\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Epoch 1 Loss: 291657.3916015625\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Epoch 2 Loss: 291915.87841796875\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Epoch 3 Loss: 291373.0576171875\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Epoch 4 Loss: 290982.1435546875\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Epoch 5 Loss: 291859.54541015625\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "Started\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "Step Completed\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n",
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 8.12 MiB is free. Process 15476 has 14.73 GiB memory in use. Of the allocated memory 14.34 GiB is allocated by PyTorch, and 242.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-874606872>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-3523702772>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step Completed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/model_weights_pytorch/model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0meval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0macc_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mcum_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcum_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-1424980800>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcap\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-4148462090>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, cap_tokens, inference)\u001b[0m\n\u001b[1;32m     32\u001b[0m           )\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           decoder_output = self.decoder_transformer(\n\u001b[0m\u001b[1;32m     35\u001b[0m               \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaption_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m               \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001b[0m\u001b[1;32m    466\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_is_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mha_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_is_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;31m# feed forward block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1471\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 8.12 MiB is free. Process 15476 has 14.73 GiB memory in use. Of the allocated memory 14.34 GiB is allocated by PyTorch, and 242.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "train_model(model,loss,optimizer,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_ovMNd8kSsNf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ovMNd8kSsNf",
    "outputId": "2dbfff70-dc95-48e2-ea55-eb3aa74a5d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n"
     ]
    }
   ],
   "source": [
    "for img,cap in train_dataloader:\n",
    "  out  = model(img,cap)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jDFp4pB1TiAB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDFp4pB1TiAB",
    "outputId": "8e952ab9-0672-4da6-8816-792905f2b7fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ll359XB8XcD1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ll359XB8XcD1",
    "outputId": "cc670b0c-e311-4153-894b-1d56ced1c282"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f121a8ca-bcf6-4aa8-a5aa-512a914d8e0b",
   "metadata": {
    "id": "f121a8ca-bcf6-4aa8-a5aa-512a914d8e0b"
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    total_acc,total_count = 0,0\n",
    "\n",
    "    for img,cap in test_dataloader:\n",
    "        img,cap = img.to(torch.device('cpu')),cap.to(torch.device('cpu'))\n",
    "        model = model.to(torch.device('cpu'))\n",
    "        output = model(img,cap,False)\n",
    "        predicted = torch.max(output.data,1)[1]\n",
    "        total_acc += (predicted == cap.float()).sum().item()\n",
    "        total_count += cap.size(0)\n",
    "\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3x5P6PVO6l4Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "3x5P6PVO6l4Q",
    "outputId": "904b0e0a-0213-473f-9082-c56b2538d0fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 50, 50])\n",
      "torch.Size([50, 1000])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3784653154>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-3511229231>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-4148462090>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, cap_tokens, inference)\u001b[0m\n\u001b[1;32m     32\u001b[0m           )\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           decoder_output = self.decoder_transformer(\n\u001b[0m\u001b[1;32m     35\u001b[0m               \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaption_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m               \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001b[0m\u001b[1;32m    466\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_is_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mha_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_is_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    862\u001b[0m     def _sa_block(self, x: Tensor,\n\u001b[1;32m    863\u001b[0m                   attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: bool = False) -> Tensor:\n\u001b[0;32m--> 864\u001b[0;31m         x = self.self_attn(x, x, x,\n\u001b[0m\u001b[1;32m    865\u001b[0m                            \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                            \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5474\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5476\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5477\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc9914-cfbf-4336-92c5-f29486a683fd",
   "metadata": {
    "id": "d9bc9914-cfbf-4336-92c5-f29486a683fd"
   },
   "outputs": [],
   "source": [
    "client = genai.Client(api_key='AIzaSyCFJ3RwiHvLTy9QYMhraasRH1D3h7zZ2G0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d3488-eda9-47a2-9c30-c05c51e2ced6",
   "metadata": {
    "id": "7c2d3488-eda9-47a2-9c30-c05c51e2ced6"
   },
   "outputs": [],
   "source": [
    "def predict(img_path):\n",
    "    img = Image.open(f\"{img_path}\").convert('RGB')\n",
    "    inp =  preprocess(img).unsqueeze(0).to(device)\n",
    "    cap = torch.tensor(vocab(tokenizer(\"<start>\")),dtype=torch.int64).unsqueeze(0).to(device)\n",
    "    print(inp.shape)\n",
    "    print(cap.shape)\n",
    "    out = model(inp,cap,True)\n",
    "    predicted = torch.argmax(out,dim=-1)\n",
    "    #predicted = torch.max(out.data,1)[1]\n",
    "    text = [vocab.lookup_token(idx) for idx in predicted[0]]\n",
    "    return text\n",
    "    #return cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HOIaPY3EXW1L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOIaPY3EXW1L",
    "outputId": "e07b1179-52c0-4af4-81e0-70dc44f9eacb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 50, 50])\n",
      "torch.Size([1, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dog',\n",
       " 'shirt',\n",
       " 'girl',\n",
       " 'play',\n",
       " 'dog',\n",
       " 'girl',\n",
       " 'girl',\n",
       " 'dog',\n",
       " 'girl',\n",
       " 'girl',\n",
       " 'shirt',\n",
       " 'girl',\n",
       " 'play',\n",
       " 'girl',\n",
       " 'dog',\n",
       " 'girl',\n",
       " 'dog',\n",
       " 'shirt',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'girl',\n",
       " 'dog',\n",
       " 'play',\n",
       " 'shirt',\n",
       " 'girl',\n",
       " 'girl',\n",
       " 'girl',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'girl',\n",
       " 'dog',\n",
       " 'play',\n",
       " 'little',\n",
       " 'girl',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'play',\n",
       " 'girl',\n",
       " 'dog',\n",
       " 'girl',\n",
       " 'play',\n",
       " 'dog',\n",
       " 'dog',\n",
       " 'shirt',\n",
       " 'girl',\n",
       " 'play',\n",
       " 'dog',\n",
       " 'girl',\n",
       " 'girl']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"/content/drive/MyDrive/Datasets/example.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36b9c7-1fa2-4ce3-b1a4-6830588f5bf7",
   "metadata": {
    "id": "2f36b9c7-1fa2-4ce3-b1a4-6830588f5bf7"
   },
   "outputs": [],
   "source": [
    "img_path = ''\n",
    "pred = predict(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e33f2-6ebd-4494-abf5-04d4ee80602a",
   "metadata": {
    "id": "050e33f2-6ebd-4494-abf5-04d4ee80602a"
   },
   "outputs": [],
   "source": [
    "user_ques = input('Enter your question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874d0d1-b5ec-44c5-af55-3f8ff04e50d8",
   "metadata": {
    "id": "8874d0d1-b5ec-44c5-af55-3f8ff04e50d8"
   },
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=pred + user_ques,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003aadce-9813-4677-918e-e0e288a05429",
   "metadata": {
    "id": "003aadce-9813-4677-918e-e0e288a05429"
   },
   "outputs": [],
   "source": [
    "response.text"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
